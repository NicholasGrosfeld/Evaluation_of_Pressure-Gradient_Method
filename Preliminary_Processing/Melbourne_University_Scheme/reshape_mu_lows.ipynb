{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f84ff63-6760-4bea-9f1a-8ffddb295690",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Jan  5 15:56:07 2023\n",
    "This code takes a .csv file of identified cyclones from the Melbourne Uni \n",
    "tracking scheme, and outputs a .txt file presenting the cyclone information in\n",
    "a format consistent with the Grosfeld et al. 2021 tracking scmeme. \n",
    "Column headings are TrackID, Year, Month, Day, Hour, Tstep, Lat, Lon. \n",
    "@author: nick\n",
    "\"\"\"\n",
    "\n",
    "# ======================== Import Modules ======================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.dates as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b123ba8a-d179-4b6b-9d17-55250c3e382e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================== Define Utility Functions =========================\n",
    "\n",
    "def netcdf_time_scale(y,m,d,h,y0):\n",
    "    \n",
    "    '''This function takes a date in y,m,d,h format and returns the value of the\n",
    "    hours since jan 1, y0 (the time convention of reanalysis). Inputs are integers. \n",
    "    Output is a float.''' \n",
    "    \n",
    "    d0 = datetime(y0,1,1,0) # the datetime object representing 12am, jan 1 of the baseline year of the reanalysis\n",
    "    d = datetime(y,m,d,h) # the datetime object for the day and time being tested\n",
    "    \n",
    "    t = 24 * (dt.date2num(d) - dt.date2num(d0)) # number of hours since 12am, jan 1 of the baseline year\n",
    "    # dt.date2num gives the number of days since the python datetime time origin. \n",
    "    \n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c5ac6f3-34f2-46a3-a3f4-2ac5df709884",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================== Set Initial Parameters ===========================\n",
    "\n",
    "dataset = 'era5'\n",
    "y0 = 1900 # Baseline year to compute the timescale value.\n",
    "\n",
    "# Time and Space boundaries for the subset\n",
    "years = (19790000, 20091100) # (19790400, 20091100) to compare against P12, (19790000, 20180000) for else.  \n",
    "                            # MU tracking scheme reccords dates as yyyymmdd.\n",
    "lats = (-30, -45) # (-30, -45) to compare against P12, (-25, -55) for else, and (-30, -45) for months and years plots\n",
    "lons = (125, 147.5) # (125, 147.5) to compare against P12, (100, 160) for else, and (-125, -147.5) for months and years plots\n",
    "\n",
    "# Data I/O parameters\n",
    "data_path = '/home/561/nxg561/00_Tracking_Scheme_Comparison/Input_Data/Acacia_Lows/'\n",
    "\n",
    "input_filename = 'UM_lows_ERA5_500hPa_proj100_rad2cv2_19592022_fixes.csv'\n",
    "output_filename = 'closed_lows_mu_era5_2009_sea.txt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e536f4e9-d76a-4ed4-bb9d-ccaa85c1418b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================== Read and Extract Data ============================\n",
    "input_lows_pd = pd.read_csv(data_path + input_filename, delimiter = ',', header = 0)\n",
    "\n",
    "input_lows_pd.columns = [' ', 'ID', 'Fix', 'Date', 'Time', 'Open', 'Lon', 'Lat', 'MSLP', 'CV', 'Depth', 'Radius', 'Up', 'Vp', 'Location']\n",
    "\n",
    "# remove open troughs and events outside the range of lats, lons and years\n",
    "closed_lows_pd = input_lows_pd.loc[(input_lows_pd['Open'] == 0) & \n",
    "                                   (input_lows_pd['Date'] > years[0]) & # These are just set to < and > because the time\n",
    "                                   (input_lows_pd['Date'] < years[1]) & # is given by yyyymmdd\n",
    "                                   (input_lows_pd['Lat'] <= lats[0]) &\n",
    "                                   (input_lows_pd['Lat'] >= lats[1]) &\n",
    "                                   (input_lows_pd['Lon'] >= lons[0]) &\n",
    "                                   (input_lows_pd['Lon'] <= lons[1])]\n",
    "\n",
    "# These columns from the MU lows are already numerical, so they just need to be\n",
    "# converted to columns of a numpy array. \n",
    "track_data = closed_lows_pd.ID.to_numpy()\n",
    "lat_data = closed_lows_pd.Lat.to_numpy()\n",
    "lon_data = closed_lows_pd.Lon.to_numpy()\n",
    "cv_data = closed_lows_pd.CV.to_numpy()\n",
    "depth_data = closed_lows_pd.Depth.to_numpy()\n",
    "radius_data = closed_lows_pd.Radius.to_numpy()\n",
    "\n",
    "# these columns need to be extracted as lists of strings to work with. \n",
    "date_um = list(closed_lows_pd.Date)\n",
    "hour_um = list(closed_lows_pd.Time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f4bdc2f9-f38c-4e3e-8944-92ed041ec0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======================== Convert Date and Time Data =========================\n",
    "\n",
    "# This section loops through the date_um and hour_um lists and computes the \n",
    "# y,m,d,h  values with the netcdf_time_scale function defined at the beginning\n",
    "# of the program. \n",
    "\n",
    "ld = np.shape(closed_lows_pd)[0]\n",
    "\n",
    "# Set up a blank array to store the output columns in. \n",
    "new_array = np.zeros((ld,11))\n",
    "\n",
    "looprange = range(0,ld)\n",
    "\n",
    "for r in looprange:\n",
    "\n",
    "    # extract the y,m,d,h from the date data.\n",
    "    y = str(date_um[r])[:4]\n",
    "    m = str(date_um[r])[4:6]\n",
    "    d = str(date_um[r])[6:]\n",
    "    h = hour_um[r][:-3]\n",
    "    \n",
    "    # Write the processed data into the new array. \n",
    "    new_array[r,1] = int(y)\n",
    "    new_array[r,2] = int(m)\n",
    "    new_array[r,3] = int(d)\n",
    "    new_array[r,4] = int(h)\n",
    "\n",
    "    # Compute a reanalysis timestep based on the era5 baseline year of 1900\n",
    "    new_array[r,5] = netcdf_time_scale(int(y), int(m), int(d), int(h), y0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7828d331-f425-494e-9fff-3fb927e09cfc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ======================== Add Final Data and Save Output =====================\n",
    "   \n",
    "new_array[:,0] = track_data\n",
    "new_array[:,6] = lat_data\n",
    "new_array[:,7] = lon_data\n",
    "new_array[:,8] = cv_data\n",
    "new_array[:,9] = depth_data\n",
    "new_array[:,10] = radius_data\n",
    "\n",
    "# Save output\n",
    "fname = data_path + output_filename\n",
    "np.savetxt(fname, new_array, delimiter = ',')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54ba65d9-a72c-4229-a5e9-122fd34aa600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code computes the month subsets. (Not used for the final paper)\n",
    "\n",
    "months = (4,10) # (4, 10) to compare against P012, (1,12) for else\n",
    "\n",
    "# Data I/O parameters\n",
    "save_path = '/home/561/nxg561/00_Tracking_Scheme_Comparison/Input_Data/Acacia_Lows/'\n",
    "\n",
    "output_filename = 'closed_lows_mu_era5_2017_nov-mar.txt'\n",
    "\n",
    "# This line selects the subset of months\n",
    "#im = (new_array[:,2] >= months[0]) & (new_array[:,2] <= months[1])\n",
    "im = np.logical_not((new_array[:,2] >= months[0]) & (new_array[:,2] <= months[1]))\n",
    "\n",
    "# Save output\n",
    "output_array = new_array[im, :]\n",
    "np.savetxt(save_path + output_filename, output_array, delimiter = ',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:analysis3-23.01]",
   "language": "python",
   "name": "conda-env-analysis3-23.01-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
