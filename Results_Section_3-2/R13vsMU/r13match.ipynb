{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3023116e-29d7-4aae-9b78-c48e7f917fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1979.    4.    4.]\n",
      "[1979.    4.    4.]\n",
      "Hits:  1201\n",
      "Hits per year:  38.74193548387097\n",
      "Misses:  241\n",
      "Misses per year:  7.774193548387097\n",
      "Extras:  692\n",
      "Extras per year:  22.322580645161292\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python2\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Mar  2 16:52:50 2018\n",
    "\n",
    "This script is for comparing two 'lists' of dates of a cut-off low, where the \n",
    "number of the events that match is the measure of success. The hits, misses and \n",
    "extra entries can be written out to a .txt file. \n",
    "\n",
    "INPUT:  -file of cut-off lows identified with tracking scheme (ncep1 only, save_path + 'cutoff_lows_ncep1.txt')\n",
    "        -file of Mike Pook's cutoff lows (pooklows_for_synoptic_comparison.txt)\n",
    "\n",
    "OUTPUT: -prints numbers of hit, missed and extra events to the screen (standard output)\n",
    "        - OPTIONAL OUTPUT:.txt file containing year, month, day, and rain of hit, \n",
    "        miss and extra low events\n",
    "\n",
    "OUTPUT FILE NAME FORMAT: save_path + 'pookhitlist.txt'\n",
    "\n",
    "@author: Nick Grosfeld\n",
    "\"\"\"\n",
    "#==============================================================================\n",
    "import numpy as np\n",
    "#import pandas as pd\n",
    "\n",
    "years = (1979,2009) # dataset overlap period \n",
    "months = (4,10) # dataset overlap period \n",
    "save_results = 1\n",
    "\n",
    "save_path = '/home/561/nxg561/00_Tracking_Scheme_Comparison/Output_Data/R13vsMU/' \n",
    "\n",
    "#==============================================================================\n",
    "# Load Mike Pook's dataset, and convert it to a 'set' (as in set theory from maths)\n",
    "\n",
    "training_dataset_filename = '/home/561/nxg561/00_Tracking_Scheme_Comparison/Input_Data/R13/pook2009lows.txt'\n",
    "training_dataset = np.loadtxt(training_dataset_filename, delimiter = ',')\n",
    "\n",
    "# This is where a subset of the training dataset could be taken.\n",
    "\n",
    "overlap_rows = (training_dataset[:,0] >= years[0]) & (training_dataset[:,0] <= years[1])\n",
    "\n",
    "training_dataset_dates = training_dataset[overlap_rows,0:3]\n",
    "print(training_dataset_dates[0,:])\n",
    "\n",
    "training_dataset_dates = map(tuple,training_dataset_dates)\n",
    "training_dataset_dates = set(training_dataset_dates)\n",
    "\n",
    "#==============================================================================\n",
    "# Load the new dataset to be tested, and convert it also to a 'set'\n",
    "\n",
    "test_dataset_filename = '/home/561/nxg561/00_Tracking_Scheme_Comparison/Input_Data/Acacia_Lows/closed_lows_mu_era5_2009_sea.txt'\n",
    "test_dataset = np.loadtxt(test_dataset_filename, delimiter = ',')\n",
    "\n",
    "overlap_rows = (test_dataset[:,1] >= years[0]) & (test_dataset[:,1] <= years[1]) & (test_dataset[:,2] >= months[0]) & (test_dataset[:,2] <= months[1])\n",
    "\n",
    "test_dataset_dates = test_dataset[overlap_rows,1:4]\n",
    "print(test_dataset_dates[0,:])\n",
    "\n",
    "test_dataset_dates = map(tuple,test_dataset_dates)\n",
    "test_dataset_dates = set(test_dataset_dates)\n",
    "\n",
    "#==============================================================================\n",
    "#Now do the intersection and difference of the sets. \n",
    "\n",
    "hit = training_dataset_dates.intersection(test_dataset_dates)\n",
    "\n",
    "miss = training_dataset_dates.difference(test_dataset_dates)\n",
    "\n",
    "extra = test_dataset_dates.difference(training_dataset_dates)\n",
    "\n",
    "#convert each of the sets of results to a list and write it to a .txt file. \n",
    "\n",
    "hitlist = list(hit)\n",
    "misslist = list(miss)\n",
    "extralist = list(extra)\n",
    "\n",
    "hits = len(hitlist)\n",
    "misses = len(misslist)\n",
    "extras = len(extralist) \n",
    "\n",
    "hits_per_year = hits/ (years[1] - years[0] + 1)\n",
    "misses_per_year = misses / (years[1] - years[0] + 1)\n",
    "extras_per_year = extras / (years[1] - years[0] + 1)\n",
    "    \n",
    "print('Hits: ', hits)\n",
    "print('Hits per year: ', hits_per_year)\n",
    "print('Misses: ', misses)\n",
    "print('Misses per year: ', misses_per_year)\n",
    "print('Extras: ', extras)\n",
    "print('Extras per year: ', extras_per_year)\n",
    "\n",
    "#==============================================================================\n",
    "\n",
    "# Create an array of the dates and rain (from Mike Pook's dataset) of the \n",
    "# cut-off lows that were missed\n",
    "lm = len(misslist)\n",
    "missarray = np.zeros((lm, 4), float)\n",
    "\n",
    "looprange = np.arange(0,lm)\n",
    "\n",
    "for r in looprange:\n",
    "    \n",
    "    date = misslist[r]    \n",
    "    y = date[0]\n",
    "    m = date[1]\n",
    "    d = date[2]\n",
    "    \n",
    "    im = (training_dataset[:,0] == y) & (training_dataset[:,1] == m) & (training_dataset[:,2] == d)\n",
    "    rain = training_dataset[im,3]\n",
    "    \n",
    "    missarray[r,0] = y\n",
    "    missarray[r,1] = m\n",
    "    missarray[r,2] = d\n",
    "    missarray[r,3] = rain\n",
    "\n",
    "# Create an array of the dates and rain of (from Mike Pook's dataset) the \n",
    "# cut-off lows that were hit    \n",
    "lh = len(hitlist)\n",
    "hitarray = np.zeros((lh, 4), float)\n",
    "\n",
    "looprange = np.arange(0,lh)\n",
    "\n",
    "for r in looprange:\n",
    "    \n",
    "    date = hitlist[r]    \n",
    "    y = date[0]\n",
    "    m = date[1]\n",
    "    d = date[2]\n",
    "    \n",
    "    ih = (training_dataset[:,0] == y) & (training_dataset[:,1] == m) & (training_dataset[:,2] == d)\n",
    "    rain = training_dataset[ih,3]\n",
    "    \n",
    "    hitarray[r,0] = y\n",
    "    hitarray[r,1] = m\n",
    "    hitarray[r,2] = d\n",
    "    hitarray[r,3] = rain\n",
    "\n",
    "# Create an array of the dates of the extra cut-off lows that were found \n",
    "le = len(extralist)\n",
    "extraarray = np.zeros((le, 3), float)\n",
    "\n",
    "looprange = np.arange(0,le)\n",
    "\n",
    "for r in looprange:\n",
    "    \n",
    "    date = extralist[r]    \n",
    "    y = date[0]\n",
    "    m = date[1]\n",
    "    d = date[2]\n",
    "    \n",
    "    extraarray[r,0] = y\n",
    "    extraarray[r,1] = m\n",
    "    extraarray[r,2] = d\n",
    "\n",
    "#==============================================================================\n",
    "    \n",
    "# Save the three result arrays as .txt files\n",
    "if save_results == 1:\n",
    "\n",
    "    output_filename = save_path + 'r13_matches.txt'\n",
    "    np.savetxt(output_filename, hitarray, delimiter=',') \n",
    "    \n",
    "    output_filename = save_path + 'r13_only.txt'\n",
    "    np.savetxt(output_filename, missarray, delimiter=',') \n",
    "    \n",
    "    output_filename = save_path + 'mu_only.txt'\n",
    "    np.savetxt(output_filename, extraarray, delimiter=',') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57dc6d4f-0a37-4b23-97c4-d5d80d3c7526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hits:  1201\n",
      "Misses:  241\n",
      "Extras:  692\n",
      "0.5627928772258669\n"
     ]
    }
   ],
   "source": [
    "print('Hits: ', len(hitlist))\n",
    "print('Misses: ', len(misslist))\n",
    "print('Extras: ', len(extralist))\n",
    "print(len(hitlist) / (len(hitlist) + len(misslist) + len(extralist)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c3aede3-4da6-4dfa-a4d6-a7c143552c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSI:\n",
      "0.5627928772258669\n"
     ]
    }
   ],
   "source": [
    "print('CSI:')\n",
    "print(hits / (hits + misses + extras))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "adfa504a-782f-41f8-be13-013e97913055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P06 percent:\n",
      "0.8328710124826629\n"
     ]
    }
   ],
   "source": [
    "print('R13 percent:')\n",
    "print(len(hitlist) / (len(hitlist) + len(misslist)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94124a4-1b48-4003-a4a4-0c01948f008b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MU percent:')\n",
    "print(len(hitlist) / (len(hitlist) + len(extralist)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8b1033-3f6d-418a-8c66-1ba7375ec2f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:analysis3]",
   "language": "python",
   "name": "conda-env-analysis3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
